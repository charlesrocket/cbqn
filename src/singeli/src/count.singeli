include './base'
include './vecfold'

if_inline (hasarch{'SSE2'}) {
  fn sum_vec{T}(v:T) = vfold{+, fold{+, mzip128{v, T**0}}}
  def fold_addw{v:T=[_]E if E<=u32} = sum_vec{T}(v)
}

def inc{ptr, ind, v} = store{ptr, ind, v + load{ptr, ind}}
def inc{ptr, ind} = inc{ptr, ind, 1}

def block_loop{V=[vec]T, n, iter} = {
  def block = (2048*8) / width{V} # Target vectors per block
  def b_max = block + block/4     # Last block max length
  assert{b_max < 1<<width{T}}     # Don't overflow count in vector section
  i:u64 = 0
  while (i < n) {
    # Number of elements to handle in this iteration
    r:u64 = n - i; if (r > vec*b_max) r = vec*block
    iter{r}
    i += r
  }
}

# Write counts /⁼x to tab and return ⌈´x
fn count{T}(tab:*usz, xp:*void, n:u64, min_allowed:T) : T = {
  def vbits = arch_defvw
  def vec = vbits/width{T}
  def uT = ty_u{T}
  def V = [vec]T
  x := *T~~xp
  mx:T = min_allowed  # Maximum of x
  block_loop{V, n, {r} => { # Handle r elements
    b := r / vec  # Vector case does b full vectors if it runs
    rv:= b * vec
    r0:u64 = 0    # Elements actually handled by vector case

    # Find range to check for suitability; return a negative if found
    # Also record number of differences dc
    # (double-counts at index vec but it doesn't need to be exact)
    xv := *V~~x
    jv := load{xv}; mv := jv; dc := -(jv != load{*V~~(x+1)})
    @for (xv, xp in *V~~(x-1) over _ from 1 to b) {
      jv = min{jv, xv}; mv = max{mv, xv}
      dc -= xp != xv
    }
    @for (x over _ from rv to r) { if (x<min_allowed) return{x}; if (x>mx) mx=x }
    jt := vfold{min, jv}
    mt := vfold{max, mv}
    if (jt < min_allowed) return{jt}
    if (mt > mx) mx = mt

    # Fast cases
    dt := promote{u64, fold_addw{dc}}
    nc := uT~~(mt - jt)  # Number of counts to perform: last is implicit
    if (dt < b * (vec/2) and dt*8 < b * promote{u64,nc}) {
      r0 = count_with_runs{V, vec, x, tab, r}
    } else if (nc <= 24*vbits/128) {
      r0 = rv
      count_by_sum{T, V, [vec]uT, xv, b, tab, r0,
        promote{u64, uT~~jt}, # Starting count
        promote{u64, nc}      # Number of iterations
      }
    }

    # Scalar fallback and cleanup
    @for (x over _ from r0 to r) inc{tab, x}
    x += r
  }}
  mx
}

# Sum comparisons against each value (except one) in the range
def count_by_sum{T, V, U, xv, b, tab, r0, j0, m} = {
  total := trunc{usz, r0}    # To compute last count
  def count_each{js, num} = {
    j := @collect (k to num) trunc{T, js+k}
    c := copy{length{j}, U**0}
    e := each{{j}=>V**j, j}
    @for (xv over b) each{{c,e} => c -= xv == e, c, e}
    def add_sum{c, j} = {
      s := promote{usz, fold_addw{c}}
      total -= s; inc{tab, j, s}
    }
    each{add_sum, c, j}
  }
  m4 := m / 4
  @for (j4 to m4) count_each{j0 + 4*j4, 4}
  @for (j from 4*m4 to m) count_each{j0 + j, 1}
  inc{tab, trunc{T, j0 + m}, trunc{usz,total}}
}

# Count adjacent equal elements at once, breaking at w-element groups
# May read up to index r from x, hitting one element that's not counted
def count_with_runs{V, vec, x, tab:*T, r} = {
  def w = width{ux}
  m0:ux = 1 << (w-1) # Last element in each chunk ends a run
  bw := r / w
  @for (i to bw) {
    xo := x + i*w
    m := m0
    # Mark the end of each run
    @unroll (j to w / vec) {
      def jv = j*vec
      def lv{k} = load{*V~~(xo + k)}
      m |= promote{ux, homMask{lv{jv} != lv{jv+1}}} << jv
    }
    # Iterate over runs
    jp:T = - T~~1
    while (m > m0) @unroll (2) {
      j := trunc{T, ctz{m}}
      inc{tab, load{xo, j}, cast_i{T, j - jp}}
      jp = j; m &= m-1
    }
    # One step if popc{m} was odd, reducing branch mispredictions above
    inc{tab, load{xo, w-1}, ((w-1) - jp) & -trunc{T, m>>(w-1)}}
  }
  bw * w
}

# Condensed version without count_by_sum
fn count_i32_i32(tab:*i32, x:*i32, n:u64) : void = {
  def T = i32
  def vbits = arch_defvw
  def vec = vbits/width{T}
  def V = [vec]T
  block_loop{V, n, {r} => {
    b := r / vec
    xv := *V~~x
    dc := -(load{xv} != load{*V~~(x+1)})
    @for (xv, xp in *V~~(x-1) over _ from 1 to b) dc -= xp != xv
    dt := promote{u64, fold_addw{dc}}
    r0:u64 = 0
    if (dt < b * (vec/2)) r0 = count_with_runs{V, vec, x, tab, r}
    @for (x over _ from r0 to r) inc{tab, x}
    x += r
  }}
}

export{'simd_count_i8',  count{i8}}
export{'simd_count_i16', count{i16}}
export{'simd_count_i32_i32', count_i32_i32}
